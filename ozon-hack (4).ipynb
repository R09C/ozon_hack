{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9275182,"sourceType":"datasetVersion","datasetId":5613552},{"sourceId":9317018,"sourceType":"datasetVersion","datasetId":5643289}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve, auc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport joblib\nimport json\nimport string\nimport re\nfrom tqdm import tqdm\nimport gc\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\n# from sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nimport logging\nfrom pprint import pprint\n# logging.getLogger('transformers').setLevel(logging.ERROR)\n# logging.getLogger('sentence_transformers').setLevel(logging.ERROR)\n# logging.getLogger('transformers').setLevel(logging.INFO)\n# logging.getLogger('sentence_transformers').setLevel(logging.INFO)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-09T14:56:50.557176Z","iopub.execute_input":"2024-09-09T14:56:50.557483Z","iopub.status.idle":"2024-09-09T14:56:50.566917Z","shell.execute_reply.started":"2024-09-09T14:56:50.557451Z","shell.execute_reply":"2024-09-09T14:56:50.565770Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    attributes_path = \"/kaggle/input/ozon-hackaton/train/attributes.parquet\"\n    resnet_path = \"/kaggle/input/ozon-hackaton/train/resnet.parquet\"\n    text_and_bert_path = \"/kaggle/input/ozon-hackaton/train/text_and_bert.parquet\"\n    train_path = \"/kaggle/input/ozon-hackaton/train/train.parquet\"\n\n    # Используем Polars для чтения файлов parquet\n    attributes = pl.read_parquet(attributes_path)\n    resnet = pl.read_parquet(resnet_path)\n    text_and_bert = pl.read_parquet(text_and_bert_path)\n    train = pl.read_parquet(train_path)\n\n    # Возвращаем только половину данных\n    print(attributes.shape)\n    print(attributes[1799186009])\n\n    print(resnet.shape)\n    print(text_and_bert.shape)\n    print(train.shape)\n    return attributes, resnet, text_and_bert, train[:250000]","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:55:51.489961Z","iopub.execute_input":"2024-09-09T14:55:51.490767Z","iopub.status.idle":"2024-09-09T14:55:51.497537Z","shell.execute_reply.started":"2024-09-09T14:55:51.490719Z","shell.execute_reply":"2024-09-09T14:55:51.496377Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def process_text_and_bert(df):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"\n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F1E0-\\U0001F1FF\"\n                           \"]+\", flags=re.UNICODE)\n    df = df.with_columns(\n        (pl.col(\"variantid\")).alias(\"variantid\"),\n        (pl.col(\"description\")\n        .fill_null(\"\")\n        .str.replace_all(r'<[^<]+?>', ' ', literal=False)\n        .str.replace_all(r'http\\S+', ' ', literal=False)\n        .str.replace_all(r'[^\\w\\s]', ' ', literal=False)\n        .str.replace_all(r'[^a-zA-Zа-яА-Я0-9]', ' ', literal=False)\n        .str.replace_all(r'<[^>]+>|&[a-zA-Z0-9#]+;', ' ', literal=False)\n        .str.to_lowercase()\n        .str.replace_all(r\"\\s+\", \" \", literal=False)\n        .alias(\"combined_text\")),\n        (pl.col(\"name_bert_64\")).alias(\"name_bert_64\")\n    )\n    df=df.with_columns(pl.col(\"combined_text\").map_elements(lambda x: emoji_pattern.sub(r[''], x),return_dtype=str).alias(\"combined_text\"))\n    df = df.drop([\"name\", \"description\"])\n    print(df.head(5))\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_data(train,attributes, resnet, text_and_bert):\n    # Оптимизация объединения данных с использованием join\n    train_data = train.join(\n        resnet.select([\"variantid\", \"main_pic_embeddings_resnet_v1\"]),\n        left_on=\"variantid1\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"main_pic_embeddings_resnet_v1\": \"pic_embeddings_1\"[0]})\n\n    train_data = train_data.join(\n        resnet.select([\"variantid\", \"main_pic_embeddings_resnet_v1\"]),\n        left_on=\"variantid2\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"main_pic_embeddings_resnet_v1\": \"pic_embeddings_2\"[0]})\n\n    train_data = train_data.join(\n        text_and_bert.select([\"variantid\", \"combined_text\",\"name_bert_64\"]),\n        left_on=\"variantid1\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"combined_text\": \"text_1\",\"name_bert_64\":\"name_bert_1\"[0]})\n\n    train_data = train_data.join(\n        text_and_bert.select([\"variantid\", \"combined_text\",\"name_bert_64\"]),\n        left_on=\"variantid2\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"combined_text\": \"text_2\",\"name_bert_64\":\"name_bert_2\"[0]})\n        \n    train_data = train_data.join(\n        attributes.select([\"variantid\", \"categories\"]),\n        left_on=\"variantid1\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"categories\": \"categories_1\"[0]})\n\n    train_data = train_data.join(\n        attributes.select([\"variantid\", \"categories\"]),\n        left_on=\"variantid2\",\n        right_on=\"variantid\",\n        how=\"left\",\n    ).rename({\"categories\": \"categories_2\"[0]})\n    return train_data.drop_nulls()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(train_data, tfidf_vectorizer):\n    num_samples = 200000\n    text_data = (train_data['text_1'][num_samples:num_samples*2] + ' ' + train_data['text_2'][num_samples:num_samples*2]).to_numpy()\n    print(train_data['text_1'].shape)\n    print(train_data['text_2'].shape)\n    print(text_data.shape)\n \n    text_embeddings = tfidf_vectorizer.fit_transform(text_data).toarray()\n    del text_data\n    print(\"Созданы text_embeddings\")\n    train_data = train_data.drop(['text_1', 'text_2',])\n    gc.collect()\n    name_bert_1 = train_data['name_bert_1'][num_samples:num_samples*2]\n    name_bert_2 = train_data['name_bert_2'][num_samples:num_samples*2]\n    print(name_bert_1.shape)\n    print(name_bert_2.shape)\n    name_bert= []\n    cosine_sim_name_bert = []\n    for i in tqdm(range(0, num_samples), desc=\"Обработка образцов\"):\n        name_bert.append(np.concatenate([name_bert_1[i].to_numpy().astype(np.float32), name_bert_2[i].to_numpy().astype(np.float32)]))\n        cosine_sim_name_bert.append(cosine_similarity(name_bert_1[i].to_numpy().astype(np.float32).reshape(1, -1), name_bert_2[i].to_numpy().astype(np.float32).reshape(1, -1)).flatten())\n    print(cosine_sim_name_bert[0].shape)\n    name_bert = np.asarray(name_bert, dtype=np.float32)\n    cosine_sim_name_bert = np.asarray(cosine_sim_name_bert, dtype=np.float32)\n    del name_bert_1\n    del name_bert_2\n    train_data = train_data.drop(['name_bert_1', 'name_bert_1'])\n    gc.collect()\n    print(\"Созданы name_bert embeddings\")\n \n    combined_embeddings = []\n    # Обработка данных пакетами\n    for i in tqdm(range(0, num_samples), desc=\"Обработка образцов\"):\n        pic_emb_1 = np.concatenate([np.array(x) for x in train_data[i,'pic_embeddings_1'].to_list()]).astype(np.float32)\n        pic_emb_2 = np.concatenate([np.array(x) for x in train_data[i,'pic_embeddings_2'].to_list()]).astype(np.float32)\n        text_emb = text_embeddings[i].astype(np.float32)\n \n        cat_1 = train_data['categorie_1_1', 'categorie_1_2', 'categorie_1_3', 'categorie_1_4'][i].to_numpy()\n        cat_2 = train_data['categorie_2_1', 'categorie_2_2', 'categorie_2_3', 'categorie_2_4'][i].to_numpy()\n        cosine_sim_attr = cosine_similarity(cat_1, cat_2)[0][0]\n        if pic_emb_1.size > 0 and pic_emb_2.size > 0:  # Убедимся, что эмбеддинги не пусты\n            cosine_sim = cosine_similarity([pic_emb_1], [pic_emb_2])[0][0]\n        else:\n            cosine_sim = 0.0\n        combined = np.concatenate([text_emb, name_bert[i], [cosine_sim], cosine_sim_name_bert[i], cat_1.flatten(), cat_2.flatten(), [cosine_sim_attr]])\n        combined_embeddings.append(combined)\n    train_data = train_data.drop(['categorie_1_1', 'categorie_1_2', 'categorie_1_3', 'categorie_1_4', 'categorie_2_1', 'categorie_2_2', 'categorie_2_3', 'categorie_2_4'])\n    del text_embeddings\n    del name_bert\n    del cosine_sim_name_bert\n    y = train_data[num_samples:num_samples*2]['target'].to_numpy()\n    del train_data\n    gc.collect()\n    print(\"Не нужные колонки удалены\")\n    X = np.vstack(combined_embeddings)\n    del combined_embeddings\n \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=23)\n    gc.collect()\n    return X_train, X_val, y_train, y_val","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:56:55.723812Z","iopub.execute_input":"2024-09-09T14:56:55.724472Z","iopub.status.idle":"2024-09-09T14:56:55.743284Z","shell.execute_reply.started":"2024-09-09T14:56:55.724431Z","shell.execute_reply":"2024-09-09T14:56:55.742196Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(X_train, y_train):\n    model = LogisticRegression(max_iter=5000)\n    model.fit(X_train, y_train)\n    joblib.dump(model, \"baseline.pkl\")\n    return model\n\n\ndef evaluate_model(model, X_val, y_val):\n    y_pred_prob = model.predict_proba(X_val)[:, 1]\n    y_pred = (y_pred_prob >= 0.5).astype(int)\n\n    precision, recall, _ = precision_recall_curve(y_val, y_pred_prob)\n    prauc = auc(recall, precision)\n    print(f\"PRAUC: {prauc[0]}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_train_data():\n    data_train_path = \"/kaggle/input/data-trian-ozon-hack/data_train.parquet\"\n    data_train = pl.read_parquet(data_train_path)\n    return data_train","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:56:59.617241Z","iopub.execute_input":"2024-09-09T14:56:59.618222Z","iopub.status.idle":"2024-09-09T14:56:59.622684Z","shell.execute_reply.started":"2024-09-09T14:56:59.618177Z","shell.execute_reply":"2024-09-09T14:56:59.621689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"attributes, resnet, text_and_bert, train = load_data()\nprint(\"данные загружены\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attributes[\"characteristic_attributes_mapping\"][4516]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1 = 0  \nt2 = 0  \nt3 = 0  \nb=0\nfor i in range(10):\n    characteristic_attributes = json.loads(attributes[\"characteristic_attributes_mapping\"][i])\n    if \"Тип\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=f\"{characteristic_attributes.get('Тип',[['']])[0]} {characteristic_attributes.get('Бренд',[''])[0]} {characteristic_attributes.get('Страна-изготовитель',[''])[0]} {characteristic_attributes.get('Материал',[''])[0]}\"\n        print(characteristic_attributes)\n        \n    elif \"Материал подошвы обуви\" in characteristic_attributes or \"Российский размер (обуви)\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=f\"{characteristic_attributes.get('Бренд в одежде и обуви',[''])[0]} {characteristic_attributes.get('Вид застёжки',[''])[0]} {characteristic_attributes.get('Вид каблука',[''])[0]} {characteristic_attributes.get('Пол',[''])[0]} {characteristic_attributes.get('Российский размер (обуви)',[''])[0]} {characteristic_attributes.get('Страна-изготовитель',[''])[0]}\"\n    elif \"Тип книги\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=f\"{characteristic_attributes.get('Автор',[''])[0]} {characteristic_attributes.get('Год выпуска',[''])[0]} {characteristic_attributes.get('Издательство',[''])[0]} {characteristic_attributes.get('Тип обложки',[''])[0]} {characteristic_attributes.get('Количество страниц',[''])[0]}\"\n    elif \"Модель процессора\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=f\"{characteristic_attributes.get('Бренд',[''])[0]} {characteristic_attributes.get('Конфигурация',[''])[0]}\"\n    elif \"Комплектация постельного белья\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=\"постельное белье\"\n    elif \"Педали велосипеда\" in characteristic_attributes or \"Диаметр колес, дюймы\" in characteristic_attributes or \"Количество колес\" in characteristic_attributes:\n        characteristic_attributes[\"Тип\"]=\"велосипед\"\n    elif \"Пульт ДУ\" in characteristic_attributes or \"Тип экрана\" in characteristic_attributes:\n         characteristic_attributes[\"Тип\"]=\"камера для машины\"\n    elif \"Предназначено для\" in characteristic_attributes:\n         characteristic_attributes[\"Тип\"]=characteristic_attributes[\"Предназначено для\"]\n    elif \"Материал тента\" in characteristic_attributes:\n         characteristic_attributes[\"Тип\"]=\"тент\"\n    elif \"Ширина ремешка, мм\" in characteristic_attributes:\n         characteristic_attributes[\"Тип\"]=\"аксесуар на руку\"\n    else:\n        t3 += 1\n\nprint(t1, t2, t3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_and_bert = process_text_and_bert(text_and_bert)\nprint(text_and_bert.shape)\nprint(\"обработка text\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Объединение данных\ntrain_data = merge_data(train,attributes, resnet, text_and_bert)\nprint(train_data.shape)\nprint(train_data.head(5))\nprint(\"данные объединены\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del attributes\ndel resnet \ndel text_and_bert\ndel train\nprint(\"attributes, resnet, text_and_bert, train - удалены\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(row):\n    parts=json.loads(row)\n    return parts[\"1\"], parts[\"2\"], parts[\"3\"], parts[\"4\"]\n\ntrain_data = train_data.with_columns([\n    pl.col(\"categories_1\").map_elements(lambda x: parse_data(x)[0],return_dtype=str).alias(\"categorie_1_1\"),\n    pl.col(\"categories_1\").map_elements(lambda x: parse_data(x)[1],return_dtype=str).alias(\"categorie_1_2\"),\n    pl.col(\"categories_1\").map_elements(lambda x: parse_data(x)[2],return_dtype=str).alias(\"categorie_1_3\"),\n    pl.col(\"categories_1\").map_elements(lambda x: parse_data(x)[3],return_dtype=str).alias(\"categorie_1_4\"),\n])\nprint(train_data.head(3))\n\ntrain_data = train_data.with_columns([\n    pl.col(\"categories_2\").map_elements(lambda x: parse_data(x)[0],return_dtype=str).alias(\"categorie_2_1\"),\n    pl.col(\"categories_2\").map_elements(lambda x: parse_data(x)[1],return_dtype=str).alias(\"categorie_2_2\"),\n    pl.col(\"categories_2\").map_elements(lambda x: parse_data(x)[2],return_dtype=str).alias(\"categorie_2_3\"),\n    pl.col(\"categories_2\").map_elements(lambda x: parse_data(x)[3],return_dtype=str).alias(\"categorie_2_4\"),\n])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import polars as pl\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\ntrain_data = train_data.with_columns([\n    pl.col(\"categorie_1_1\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_1_2\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_1_3\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_1_4\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_2_1\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_2_2\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_2_3\").str.to_lowercase().cast(pl.Utf8),\n    pl.col(\"categorie_2_4\").str.to_lowercase().cast(pl.Utf8),\n])\n\n\nfor i in ['categorie_1_1', 'categorie_1_2', 'categorie_1_3', 'categorie_1_4', 'categorie_2_1', 'categorie_2_2', 'categorie_2_3', 'categorie_2_4']:\n    combined_categories = train_data[f'{i[0]}'].to_list()\n    encoded_categories = label_encoder.fit_transform(combined_categories).astype('int16')\n    train_data = train_data.with_columns(\n        pl.Series(f'{i[0]}', encoded_categories),\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = load_train_data()\nprint(\"data_train загружен\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:57:14.730691Z","iopub.execute_input":"2024-09-09T14:57:14.731100Z","iopub.status.idle":"2024-09-09T14:57:26.887598Z","shell.execute_reply.started":"2024-09-09T14:57:14.731059Z","shell.execute_reply":"2024-09-09T14:57:26.886595Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"data_train загружен\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_features=3200)\nX_train, X_val, y_train, y_val = prepare_data(train_data, tfidf_vectorizer)\nprint(\"данные разбиты на train и val\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T14:57:26.889793Z","iopub.execute_input":"2024-09-09T14:57:26.890212Z","iopub.status.idle":"2024-09-09T15:03:15.196716Z","shell.execute_reply.started":"2024-09-09T14:57:26.890156Z","shell.execute_reply":"2024-09-09T15:03:15.195693Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(1168516,)\n(1168516,)\n(200000,)\nСозданы text_embeddings\n(200000,)\n(200000,)\n","output_type":"stream"},{"name":"stderr","text":"Обработка образцов: 100%|██████████| 200000/200000 [01:02<00:00, 3208.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"(1,)\nСозданы name_bert embeddings\n","output_type":"stream"},{"name":"stderr","text":"Обработка образцов: 100%|██████████| 200000/200000 [03:51<00:00, 864.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Не нужные колонки удалены\nданные разбиты на train и val\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_data\nprint(\"train_data удален\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:03:15.198126Z","iopub.execute_input":"2024-09-09T15:03:15.198540Z","iopub.status.idle":"2024-09-09T15:03:15.549856Z","shell.execute_reply.started":"2024-09-09T15:03:15.198492Z","shell.execute_reply":"2024-09-09T15:03:15.548780Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"train_data удален\n","output_type":"stream"}]},{"cell_type":"code","source":"joblib.dump(tfidf_vectorizer, \"vectorizer.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:03:15.552434Z","iopub.execute_input":"2024-09-09T15:03:15.553312Z","iopub.status.idle":"2024-09-09T15:03:19.015269Z","shell.execute_reply.started":"2024-09-09T15:03:15.553257Z","shell.execute_reply":"2024-09-09T15:03:19.014309Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['vectorizer.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"class IDECModel(nn.Module):\n    def __init__(self, input_dim, embedding_dim):\n        super(IDECModel, self).__init__()\n        \n        # Кодер\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 500),\n            nn.ReLU(),\n            nn.Linear(500, embedding_dim)\n        )\n        \n        # Декодер\n        self.decoder = nn.Sequential(\n            nn.Linear(embedding_dim, 500),\n            nn.ReLU(),\n            nn.Linear(500, input_dim)  # выходной размер должен совпадать с input_dim\n        )\n\n    def forward(self, x):\n        # Кодирование\n        embedding = self.encoder(x)\n        \n        # Декодирование\n        reconstruction = self.decoder(embedding)\n        \n        return reconstruction, embedding\n\n\ndef train_IDEC(model, data, num_clusters, num_epochs=10):\n    model.to(device)  # Переносим модель на устройство\n    data = data.to(device)  # Переносим данные на устройство\n    \n    # Инициализация KMeans\n    kmeans = KMeans(n_clusters=num_clusters, n_init='auto')\n    \n    # Начальная инициализация кластерных центров\n    embeddings = model.encoder(data).detach().cpu().numpy()\n    kmeans.fit(embeddings)\n    cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32).to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = torch.nn.MSELoss()\n    \n    for epoch in range(num_epochs):\n        model.train()  # Устанавливаем модель в режим обучения\n        \n        # Прямой проход\n        reconstructions, embeddings = model(data)\n        \n        # Вычисление потерь\n        loss_reconstruction = criterion(reconstructions, data)\n        loss_cluster = torch.mean(torch.norm(embeddings.unsqueeze(1) - cluster_centers, dim=2))\n        \n        # Общая потеря\n        loss = loss_reconstruction + loss_cluster\n        \n        # Обратное распространение и обновление параметров\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:03:19.016660Z","iopub.execute_input":"2024-09-09T15:03:19.017075Z","iopub.status.idle":"2024-09-09T15:03:19.391509Z","shell.execute_reply.started":"2024-09-09T15:03:19.017029Z","shell.execute_reply":"2024-09-09T15:03:19.390607Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_model2(X_train, y_train, cat_features=None):\n    model = CatBoostClassifier(task_type='GPU', iterations=9000, learning_rate=0.005, depth=9, verbose=200, bagging_temperature = 0.5)\n    \n    model.fit(X_train, y_train, cat_features=cat_features)\n    return model\n\ndef evaluate_model2(model, X_val, y_val):\n    y_pred_prob = model.predict_proba(X_val)[:, 1]\n    y_pred = (y_pred_prob >= 0.5).astype(int)\n\n    precision, recall, _ = precision_recall_curve(y_val, y_pred_prob)\n    prauc = auc(recall, precision)\n    print(f\"PRAUC: {prauc}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:03:19.392609Z","iopub.execute_input":"2024-09-09T15:03:19.393054Z","iopub.status.idle":"2024-09-09T15:03:19.399755Z","shell.execute_reply.started":"2024-09-09T15:03:19.393019Z","shell.execute_reply":"2024-09-09T15:03:19.398672Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = train_model2(X_train, y_train)\njoblib.dump(model, \"baseline_catboost_350k_v3.pkl\")\nevaluate_model2(model, X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:03:19.400995Z","iopub.execute_input":"2024-09-09T15:03:19.401298Z","iopub.status.idle":"2024-09-09T15:31:16.675437Z","shell.execute_reply.started":"2024-09-09T15:03:19.401264Z","shell.execute_reply":"2024-09-09T15:31:16.674261Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"0:\tlearn: 0.6921859\ttotal: 2.88s\tremaining: 7h 11m 55s\n400:\tlearn: 0.5864644\ttotal: 1m 3s\tremaining: 22m 36s\n600:\tlearn: 0.5745334\ttotal: 1m 32s\tremaining: 21m 33s\n800:\tlearn: 0.5660990\ttotal: 2m 1s\tremaining: 20m 44s\n1000:\tlearn: 0.5595598\ttotal: 2m 30s\tremaining: 20m 3s\n1200:\tlearn: 0.5540097\ttotal: 2m 59s\tremaining: 19m 26s\n1400:\tlearn: 0.5491921\ttotal: 3m 28s\tremaining: 18m 51s\n1600:\tlearn: 0.5449351\ttotal: 3m 57s\tremaining: 18m 17s\n1800:\tlearn: 0.5409196\ttotal: 4m 26s\tremaining: 17m 45s\n2000:\tlearn: 0.5373727\ttotal: 4m 55s\tremaining: 17m 13s\n2200:\tlearn: 0.5338834\ttotal: 5m 24s\tremaining: 16m 42s\n2400:\tlearn: 0.5304591\ttotal: 5m 53s\tremaining: 16m 12s\n2600:\tlearn: 0.5271096\ttotal: 6m 22s\tremaining: 15m 42s\n2800:\tlearn: 0.5237672\ttotal: 6m 52s\tremaining: 15m 12s\n3000:\tlearn: 0.5205166\ttotal: 7m 21s\tremaining: 14m 43s\n3200:\tlearn: 0.5173701\ttotal: 7m 51s\tremaining: 14m 14s\n3400:\tlearn: 0.5144698\ttotal: 8m 20s\tremaining: 13m 44s\n3600:\tlearn: 0.5115798\ttotal: 8m 50s\tremaining: 13m 15s\n3800:\tlearn: 0.5087459\ttotal: 9m 20s\tremaining: 12m 46s\n4000:\tlearn: 0.5061005\ttotal: 9m 50s\tremaining: 12m 17s\n4200:\tlearn: 0.5034942\ttotal: 10m 19s\tremaining: 11m 48s\n4400:\tlearn: 0.5009216\ttotal: 10m 49s\tremaining: 11m 18s\n4800:\tlearn: 0.4959734\ttotal: 11m 49s\tremaining: 10m 20s\n5000:\tlearn: 0.4935818\ttotal: 12m 18s\tremaining: 9m 50s\n5200:\tlearn: 0.4911991\ttotal: 12m 48s\tremaining: 9m 21s\n5400:\tlearn: 0.4889096\ttotal: 13m 18s\tremaining: 8m 52s\n5600:\tlearn: 0.4867103\ttotal: 13m 48s\tremaining: 8m 22s\n5800:\tlearn: 0.4845068\ttotal: 14m 18s\tremaining: 7m 53s\n6000:\tlearn: 0.4823899\ttotal: 14m 48s\tremaining: 7m 24s\n6200:\tlearn: 0.4802410\ttotal: 15m 18s\tremaining: 6m 54s\n6400:\tlearn: 0.4781492\ttotal: 15m 48s\tremaining: 6m 25s\n6600:\tlearn: 0.4761002\ttotal: 16m 19s\tremaining: 5m 55s\n6800:\tlearn: 0.4741003\ttotal: 16m 49s\tremaining: 5m 26s\n7000:\tlearn: 0.4721595\ttotal: 17m 18s\tremaining: 4m 56s\n7200:\tlearn: 0.4700769\ttotal: 17m 49s\tremaining: 4m 27s\n7400:\tlearn: 0.4681077\ttotal: 18m 19s\tremaining: 3m 57s\n7600:\tlearn: 0.4662366\ttotal: 18m 49s\tremaining: 3m 27s\n7800:\tlearn: 0.4643257\ttotal: 19m 19s\tremaining: 2m 58s\n8000:\tlearn: 0.4624425\ttotal: 19m 50s\tremaining: 2m 28s\n8200:\tlearn: 0.4605481\ttotal: 20m 20s\tremaining: 1m 58s\n8400:\tlearn: 0.4587055\ttotal: 20m 50s\tremaining: 1m 29s\n8600:\tlearn: 0.4568791\ttotal: 21m 20s\tremaining: 59.4s\n8800:\tlearn: 0.4550464\ttotal: 21m 51s\tremaining: 29.6s\n8999:\tlearn: 0.4532972\ttotal: 22m 21s\tremaining: 0us\nPRAUC: 0.8168522100069147\n","output_type":"stream"}]},{"cell_type":"code","source":"del model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}